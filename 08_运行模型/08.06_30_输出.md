
* 对于 RetVal 节点，其调用时序为： set_ret_val -> get_ret_val。前者由 RetVal完成，后者由 DirectSession 完成。
```
struct RetvalOp : OpKernel {
    explicit RetvalOp(OpKernelConstruction* ctx) : OpKernel(ctx) {
        ctx->GetAttr("T", &dtype_);
        ctx->GetAttr("index", &index_);
    }
    void Compute(OpKernelContext* ctx) override {
        // get upstream op's output.
        const Tensor& val = ctx->input(0);
        auto frame = ctx->call_frame();
        frame->SetRetval(index_, val);
    }
    private:
        int index_;
        DataType dtype_;
};
```
* 等所有 Executor 运行结束后， DirectSession 便可以从 FunctionCallFrame 中取出所有输出值，并将其放置在 outputs，并返回 Client。
```
Status DirectSession::Run(const RunOptions& run_options,const NamedTensorList& inputs,const std::vector<string>& output_names,
    const std::vector<string>& target_nodes,std::vector<Tensor>* outputs,RunMetadata* run_metadata) {
    // 1. prune graph
    // 2. split graph into partition by devices
    // 3. lauch executor per partition
    // 3.1 construct FunctionCallFrame
    FunctionCallFrame call_frame(executors_and_keys->input_types,executors_and_keys->output_types);
    // 3.2 frame.set_args(inputs)
    // 3.2.1 construct feeds list
    gtl::InlinedVector<Tensor, 4> feed_args(inputs.size());
    for (const auto& it : inputs) {
        // (first, second) => (tensor_name, tensor)
        feed_args[executors_and_keys->input_name_to_index[it.first]] = it.second;
    }
    // 3.2.2 frame.set_args(feeds)
    call_frame.SetArgs(feed_args);
    // 3.3 concurent execution
    RunState run_state(&devices_);
    run_state.rendez = new IntraProcessRendezvous(device_mgr_.get());
    // 3.3.1 notify when finished.
    size_t num_executors = executors_and_keys->items.size();
    ExecutorBarrier* barrier = new ExecutorBarrier(
    num_executors, run_state.rendez, [&run_state](const Status& ret) {
        {
        mutex_lock l(run_state.mu_);
        run_state.status.Update(ret);
        }
        run_state.executors_done.Notify();
    });
    Executor::Args args;
    args.call_frame = &call_frame;
    args.rendezvous = run_state.rendez;
    args.runner = [this, pool](Executor::Args::Closure c) {
    SchedClosure(pool, std::move(c));
    };
    // 3.3.2 lauch all executors.
    for (const auto& item : executors_and_keys->items) {
        item.executor->RunAsync(args, barrier->Get());
    }
    // 3.3.3 wait until all executors finished.
    WaitForNotification(&run_state,&step_cancellation_manager,GetTimeoutInMs(run_options));
    // 3.4 fetch outputs.
    // 3.4.1 frame.get_get_ret_vals
    std::vector<Tensor> sorted_outputs;
    Status s = call_frame.ConsumeRetvals(&sorted_outputs);
    // 3.4.2 emplace to outputs, and return to client.
    outputs->reserve(sorted_outputs.size());
    for (int i = 0; i < output_names.size(); ++i) {
        const string& output_name = output_names[i];
        outputs->emplace_back(std::move(sorted_outputs[executors_and_keys->output_name_to_index[output_name]]));
    }
}
```

> 在最后一公里，还要探究三件事情。
1. SendOp 与 RecvOp 的工作原理
2. IntraProcessRendezvous 的工作原理
3. Executor 的调度算法


