
* 在某个设备上， PartitionGraph 的起始节点为 Arg 节点，结束节点为 RetVal 节点。
整个过程可以看成函数调用过程， Arg 用于传递函数参数， RetVal 用于返回函数值。
* 更确切地说， Arg 完成 PartitionGraph 的输入， RetVal 完成 PartitionGraph 的输出。
对于 Arg 节点，其调用时序为： set_arg -> get_arg。其中，前者由 DirectSession 在启动Executor 列表之前，
通过调用 FunctionCallFrame.SetArgs(feeds)，传递输入参数列表的值；后者由 Arg 的 Kernel 实现调用。
```
Status DirectSession::Run(const RunOptions& run_options,const NamedTensorList& inputs,const std::vector<string>& output_names,
    const std::vector<string>& target_nodes,std::vector<Tensor>* outputs,RunMetadata* run_metadata) {
    // 1. prune graph
    // 2. split graph into partition by devices
    // 3. lauch executor per partition
    // 3.1 construct FunctionCallFrame
    FunctionCallFrame call_frame(executors_and_keys->input_types,executors_and_keys->output_types);
    // 3.2 frame.set_args(inputs)
    // 3.2.1 construct feeds list
    gtl::InlinedVector<Tensor, 4> feed_args(inputs.size());
    for (const auto& it : inputs) {
        // (first, second) => (tensor_name, tensor)
        feed_args[executors_and_keys->input_name_to_index[it.first]] = it.second;
    }
    // 3.2.2 frame.set_args(feeds)
    call_frame.SetArgs(feed_args);
    // 3.3 concurent execution
    // for (executor, partition) in executors_and_partitions:
    // executor.run(partition)
    // 3.4 fetch outputs.
}
```
* frame.get_arg 则由 Arg 来获取，并且 Arg 将其输出到 PartitionGraph 中的第一个计算节点。
```
struct ArgOp : OpKernel {
    explicit ArgOp(OpKernelConstruction* ctx) : OpKernel(ctx) {
        ctx->GetAttr("T", &dtype_);
        ctx->GetAttr("index", &index_);
    }
    void Compute(OpKernelContext* ctx) override {
        auto frame = ctx->call_frame();
        Tensor val;
        frame->GetArg(index_, &val);
        // put it into downsteram op's input.
        ctx->set_output(0, val);
    }
    private:
        int index_;
        DataType dtype_;
};
```