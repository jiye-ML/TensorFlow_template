
* tfrecords文件的读取和加载是相对比较复杂的，本文也总结了几个固定的步骤：

  * 第一步: 定义一个reader对象，和定义tfrecords文件从哪里来。

    ```python
    filename_queue=tf.train.string_input_producer(['titanic_train.tfrecords'])
    
    reader = tf.TFRecordReader()
    ```

  *  第二步：从tfrecords文件中解析保存的样本数据格式

  * 第三步：从样本数据中一次性读取一个批次的数据，即填充满一个batch。因为在深度学习进行训练的时候，往往都是一次训练多少组，以多少组为一个batch，所以需要包装。

> 上面三个步骤的**核心函数解析：**
>
> 第一步：
>
> `filename_queue=tf.train.string_input_producer(['titanic_train.tfrecords'])`
>
> 它告诉我们tfrecords文件从哪里来，注意，参数里面的中括号不能丢！
>
> `reader = tf.TFRecordReader()`
>
> 定义一个reader对象，该对象负责从tfrecords文件中读取。
>
> `_,serialized_example=reader.read(filename_queue)`
>
> 它返回的是(key,value)的元祖形式。上面的serialized_example是无法直接查看的，需要去按照特征进行解析。
>
>
>
> 第二步：解析数据
>
> `featurestf.parse_single_example(serialized_example,features={...})`
>
> 将数据的特征解析出来
>
>
>
> 第三步：每次将数据包装成一个batch。
>
> `tf.train.batch([age,sex,pclass,parch,sibsp,fare,label], batch_size=16, capacity=500)`
>
> 第一个参数就是特征的名称，中括号不能掉，第二个是batch_size的大小，这个capacity后面会解释到。

*  但是上面的步骤完成之后，我还只能够看到每一个特征的维度信息，还不能够获取具体的数值，要想获取具体的数值，依然需要在会话对象Session里面进行查看，而且步骤分为以下几步（续接前面）：



  第四步：首先在session里面创建Coordinator对象，他负责实现数据输入线程的同步，实现如下

  coord = tf.train.Coordinator()



  第五步：启动队列

  threads=tf.train.start_queue_runners(sess=sess, coord)



  第六步：这里就可以查看样本数据，将获取的样本数据“喂”给网络进行训练。



  第七步：线程同步

  coord.request_stop()

  coord.join(threads=threads)
