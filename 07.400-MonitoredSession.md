
* 训练一个简单的模型，可以通过运行 train_op 数次直至模型收敛，最终将训练参数实施 Checkpoint，持久化训练模型。
对于小规模的学习模型，这个过程至多需要花费数小时的时间。
* 但是，对于大规模的学习模型，需要花费数天时间；而且可能需要使用多份复本,此时需要更加健壮的训练过程支持模型的训练。因此，需要解决三个基本问题
    1. 当训练过程异常关闭，或程序崩溃，能够合理地处理异常；
    2. 当异常关闭，或程序崩溃之后，能够恢复训练过程；
    3. 能够通过 TensorBoard 监控整个训练过程。
    
    
    
    
    


#### 引入 MonitoredSession
* tf.train.MonitoredSession，它可以定制化 Hook，用于监听整个 Session 的生命周期；
内置 Coordinator 对象，用于协调所有运行中的线程同时停止，并监听，上报和处理异常；
当发生 AbortedError 或 UnavailableError 异常时，可以重启 Session。
