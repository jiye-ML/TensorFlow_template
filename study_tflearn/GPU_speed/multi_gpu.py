'''    使用多个 GPU 训练神经网络 '''from datetime import  datetimeimport osimport timeimport tensorflow as tfimport  mnist_inferenceBATCH_SIZE = 100LEARNING_RATE_BASE = 0.001LEAENING_RATE_DECAY = 0.99REGULAZATION_RATE = 0.0001TRAINING_STEPS = 1000MOVING_AVERAGE_DECAY = 0.99N_GPU = 4MODEL_SAVE_PATH = 'path/to/logs_and_models/'MODEL_NAME = 'model.ckpt'# 为不同的GPU提供不同的训练数据DATA_PATH = '/path/to/data.tfrecords'def get_input():    filename_queue = tf.train.string_input_producer([DATA_PATH])    reader = tf.TFRecordReader()    _, serialized_example = reader.read(filename_queue)    # 定义数据解析格式    features = tf.parse_sigle_example(        serialized_example,        features = {            'image_raw': tf.FixedLenFeature([], tf.string),            'pixels': tf.FixedLenFeature([], tf.int64),            'label': tf.FixedLenFeature([], tf.int64)        }    )    # 解析图片和标签信息    decoded_image = tf.decode_raw(features['image_raw'], tf.uint8)    reshape_image = tf.reshape(decoded_image, [784])    retyped_image = tf.cast(reshape_image, tf.float32)    label = tf.cast(features['label'], tf.int32)    # 定义输入队列并返回    min_after_dequeue = 10000    capacity = min_after_dequeue + 3 * BATCH_SIZE    return tf.train.shuffle_batch(        [retyped_image, label],        batch_size=BATCH_SIZE,        capacity=capacity,        min_after_dequeue=min_after_dequeue    )def get_loss(x, y_, regularizer, scope):    y = mnist_inference.inference(x, regularizer)    cross_entropy = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(y, y_))    regularization_loss = tf.add_n(tf.get_collection("losses", scope))    loss = cross_entropy + regularization_loss    return loss# 计算一个变量的枚举平均值def average_gradients(tower_grads):    average_grads = []    # 计算所有的变量在不同GPU上 计算得出的梯度    for grad_and_vars in zip(*tower_grads):        grads = []        for g, _ in grad_and_vars:            expanded_g = tf.expand_dims(g, 0)            grads.append(expanded_g)        grad = tf.concat(grads, 0)        grad = tf.reduce_mean(grad, 0)        v = grad_and_vars[0][1]        grad_and_var = (grad, v)        # 将变量和它的平均梯度对应起来        average_grads.append(grad_and_var)    # 返回所有变量的平均梯度， 这将被用于变量更新    return average_grads# 主训练过程def main(argv = None):    # 将简单的运算放在CPU上， 只有神经网络的训练过程放在GPU上    x, y_ = get_input()    regularizer = tf.contrib.layers.l2_regularizer(REGULAZATION_RATE)    global_step = tf.get_variable('global_step', [], initializer=tf.constant_initializer(0), trainable=False)    learning_rate = tf.train.exponential_decay(LEARNING_RATE_BASE, global_step, 60000 / BATCH_SIZE, LEAENING_RATE_DECAY)    # 定义优先方法    opt = tf.train.GradientDescentOptimizer(learning_rate)    tower_grads = []    # 将神经网络的优化过程跑在不同的GPU上    for i in range(N_GPU):        with tf.device("/gpu:%d" % i):            with tf.variable_scope("GPU_{}".format(i)) as scope:                cur_loss = get_loss(x, y_, regularizer, scope)                tf.get_variable_scope().reuse_variables()                grads = opt.compute_gradients(cur_loss)                tower_grads.append(grads)    grads = average_gradients(tower_grads)    for grad, var in grads:        if grad is not None:            tf.summary.histogram('gradients_on_average/{}'.format(var.op.name), grad)    # 使用平均梯度更新参数    apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)    for var in tf.trainable_variables():        tf.summary.histogram(var.op.name, var)    # 计算变量的滑动平均值    variable_averages = tf.train.ExponentialMovingAverage(        MOVING_AVERAGE_DECAY, global_step    )    variable_averages_op = variable_averages.apply(tf.trainable_variables())    # 每一轮迭代需要更新的取值并更新滑动    train_op = tf.group(apply_gradient_op, variable_averages_op)    saver = tf.trainable_variables()    summary_op = tf.summary.merge_all()    with tf.Session(config=tf.ConfigProto(        allow_soft_placement=True,        log_device_placement=True    )) as sess:        sess.run(tf.global_variables_initializer())        coord = tf.train.coordinator()        threads = tf.train.start_queue_runners(sess=sess, coord=coord)        summary_writer = tf.summary.FileWriter(MODEL_SAVE_PATH, sess.graph)        for step in range(TRAINING_STEPS):            start_time = time.time()            _, loss_value = sess.run([train_op, cur_loss])            duration = time.time() - start_time            if step != 0 and step % 10 == 0:                num_examples_per_step = BATCH_SIZE * N_GPU                examples_per_sec = num_examples_per_step / duration                sec_per_batch = duration / N_GPU                format_str = ('step {}, loss = {:.2f} ({:.1f} examples / sec; {:3f} sec / batch)'.format(                    step, loss_value, examples_per_sec, sec_per_batch                ))                print(format_str)                summary = sess.run(summary_op)                summary_writer.add_summary(summary, step)                if step % 1000 == 0 or (step + 1) == TRAINING_STEPS:                    checkpoint_path = os.path.join(                        MODEL_SAVE_PATH, MODEL_NAME                    )                coord.request_stop()                coord.join(threads)if __name__ == '__main__':    tf.app.run()