
* 上面是对titanic的CSV文件进行的操作，那如果是图像数据呢，难道是对图像的每一个像素进行Feature的转换吗？那么当一个图片很大的时候，像素很多，这样显然不合理，对于图像的操作这里就关键用到了BytesList去实现，下面以图像为例加以说明

* 本文没有选择很多的图片，仅仅以三张图片为例，在百度图片下载任意三张图片，因为大小不一样，使用Photoshop将三张图片简单更改为500x500大小。

```python
import tensorflow as tf
import pandas as pd
from PIL import Image
import numpy as np

#第一步：获取原始数据,此处为原始图像
img1=Image.open('picture dataset\img1.jpg')
img2=Image.open('picture dataset\img2.jpg')
img3=Image.open('picture dataset\img3.jpg')
images=[img1,img2,img3]
print(img1.size,img2.size,img3.size)
label1=np.array([1,0,0])
label2=np.array([0,1,0])
label3=np.array([0,0,1])
labels=[label1,label2,label3]

#第二步：定义record文件
tfrecord_file='picture_train.tfrecords'
writer=tf.python_io.TFRecordWriter(tfrecord_file)

#第三步：每一次写入一条样本记录
for i in range(len(images)):
    features=tf.train.Features(feature={'Picture':tf.train.Feature(bytes_list=tf.train.BytesList(value=[images[i].tobytes()])),
                                        'Label':tf.train.Feature(bytes_list=tf.train.BytesList(value=[labels[i].tobytes()]))
                                         })
    #每一条样本的特征，将一系列特征组织成一条样本
    example=tf.train.Example(features=features)
    #将每一条样本写入到tfrecord文件
    writer.write(example.SerializeToString())
writer.close()
print('写入tfrecords文件完毕！')
```

* 运行上面的代码，已经有一个2198KB大小的picture_train.tfrecords文件。上面的代码可以看出，对于图像数据，规则基本上是一模一样的，区别在于数据的初始化处理，另外，图片数据不是一个一个像素进行存取的，需要将图片以及独热编码的标签转化为原生的bytes数据格式即可。
